right, so next, let’s briefly discuss our problem more formally. the problem of nonnegative matrix factorization can be formulated mathematically as follows, with the constraint that W and H must be nonnegative matrices.
as you might have noticed, the use of the frobenius norm implies that the noise is assumed to be gaussian, which is often, a reasonable assumption to make, but this is not always the case; a lot of other possibilities for the objective function include the use of the kullback-leibler divergence, which is prevalent in text mining, the itakura-saito distance which appears in the domain of music analysis, or even the ever-present l1 norm can be used to improve robustness against outliers. the list might as well be infinite

now, when using nonnegative matrix factorization in practice, several issues must be taken care of:
 - first of all, nonnegative matrix factorization is an np-hard problem, because of the nonnegativity constraints i mentioned previously; as a matter of fact, in the unconstrained case, we can arrive at a solution for our problem efficiently using the singular value decomposition which was covered in quite some depth during the first half of this class.
in practice however, the algorithms we use for nonnegative matrix factorization are based on certain assumptions about the problem we’re trying to solve, and use heuristic solutions. luckily, this means that most problems can be solved efficiently, although this efficient algorithm is not necessarily exact.
- next, nonnegative matrix factorization is an ill-posed problem, as there usually exist multiple equivalent acceptable factorizations for a given matrix X.
now, to us engineers with applications in mind, this non uniqueness is only a problem when these different factorizations also generate different interpretations.
this issue is tackled in practice by using certain priors, with the main one being sparsity, on the factors W and H, as well as adding appropriate regularization terms in the objective function.
as you might have guessed by now the design and algorithmic implementation of such application-specific models is a very active area of research!
- finally, a last problem to be mindful of is the choice of the factorization rank r, which can be fairly difficult in practice. several approaches are used: first, trial and error, where we try different values of r and select the one which yields the best results. another possibility is to estimate r based on the singular value decomposition, and if you’re lucky, you might even be able to use some expert knowledge about the problem at hand. An example of this is in the scenario of hyperspectral unmixing we talked about earlier, where the number of endmembers could provide a good guess for r.