\documentclass[11pt]{article}
\usepackage[a4paper,left=1.5cm,right=1.5cm,top=1.5cm,bottom=1.5cm]{geometry}
\usepackage{fancyhdr}
\usepackage{mleftright}
\usepackage{verbatim}
\renewcommand{\headrulewidth}{1pt}
\fancyhead[C]{\textsc{[LINMA2380] --- Homework 3}}
\fancyhead[L]{23 November 2020}
\fancyhead[R]{Group 02}

\usepackage{tikz}
\usepackage{pgfplots}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{csquotes}
\usepackage{mathtools,amssymb,amsthm}
\usepackage[binary-units=true,separate-uncertainty = true,multi-part-units=single]{siunitx}
\usepackage{float}
\usepackage[linktoc=all]{hyperref}
\hypersetup{breaklinks=true}
\graphicspath{{img/}}
\usepackage{caption}
\usepackage{textcomp}
\usepackage{array}
\usepackage{color}
\usepackage{tabularx,booktabs}
\usepackage{titlesec}
\usepackage{wrapfig}
\pagestyle{fancy}
\usepackage{mathrsfs}
\usepackage{bm}
\DeclarePairedDelimiterX{\norm}[1]{\lVert}{\rVert}{#1}

\newcommand\bovermat[2]{%
  \makebox[0pt][l]{$\smash{\overbrace{\phantom{%
    \begin{matrix}#2\end{matrix}}}^{\text{#1}}}$}#2}
    
\newcommand{\imag}{\mathrm{i}\mkern1mu} % Imaginary unit
\newcommand{\abs}[1]{\left\lvert#1\right\lvert}
\usepackage{listings}
\lstset{
	language=Python,
	numbers=left,
	numberstyle=\tiny\color{gray},
	basicstyle=\rm\small\ttfamily,
	keywordstyle=\bfseries\color{dkred},
	frame=single,
	commentstyle=\color{gray}=small,
	stringstyle=\color{dkgreen},
	%backgroundcolor=\color{gray!10},
	%tabsize=8, % Thank you Papa Torvalds
	%rulecolor=\color{black!30},
	%title=\lstname,
	breaklines=true,
	framextopmargin=2pt,
	framexbottommargin=2pt,
	extendedchars=true,
	inputencoding=utf8,
}

\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\vect}{vec}
\DeclareMathOperator{\newdiff}{d} % use \dif instead
\newcommand{\dif}{\newdiff\!}
\newcommand{\e}{\mathrm{e}}

\newcommand{\field}{\mathbb{F}} % field
\newcommand{\real}{\mathbb{R}} % real numbers
\newcommand{\complex}{\mathbb{C}} % complex numbers

\newcommand{\snorm}[1]{\norm{#1}_2} % spectral norm
\newcommand{\fnorm}[1]{\norm{#1}_F} % frobenius norm

\setcounter{MaxMatrixCols}{15}

\newcommand\undermat[2]{% http://tex.stackexchange.com/a/102468/5764
	\makebox[0pt][l]{$\smash{\underbrace{\phantom{%
					\begin{matrix}#2\end{matrix}}}_{\text{$#1$}}}$}#2}

\begin{document}
\section*{Exercise A: Boundedness of trajectories and Lyapunov equation}
\subsection*{A1}
\subsection*{A2}
We assume that $A=J_n(\lambda)$. Hence we can write :
\begin{equation*}
    x(t)=e^{At}x(0)=e^{J_n(\lambda)t}x(0)
\end{equation*}
We can use the result of question B4 from Homework 1 which develops $e^{J_n(\lambda)}$:
\begin{align*}
    x(t)&=e^{J_n(\lambda)t}x(0)\\
    &=e^{\lambda t}\Bigg(I+\sum_{k=1}^{n-1}\frac{1}{k!}\big(J_n(0)\big)^k\Bigg)^t x(0)\\
    &=e^{\lambda t}e^{J_n(0) t} x(0)\\
    &=e^{\lambda t}\Bigg(I+\sum_{k=1}^{n-1}\frac{1}{k!}\big(J_n(0) t\big)^k\Bigg) x(0)\\
    &=e^{\lambda t}\Bigg(I+\sum_{k=1}^{n-1}\frac{1}{k!}J_n^k(0) t^k\Bigg) x(0)
\end{align*}
The third and fourth equalities come from the definition of the matrix exponential. We can now develop the terms in parentheses : 
\begin{align*}
    I+\sum_{k=1}^{n-1}\frac{1}{k!}J_n^k(0) t^k = I &+ \frac{t}{1!}
    \begin{pmatrix}
    0&1&&\\
    &\ddots&\ddots&&\\
    &&0&1&\\
    &&&0&1\\
    &&&&0
    \end{pmatrix} + \frac{t^2}{2!}
    \begin{pmatrix}
    0&0&1&\\
    &\ddots&\ddots&\ddots&\\
    &&0&0&1\\
    &&&0&0\\
    &&&&0
    \end{pmatrix}\\ \\
    &+ \dots +\frac{t^k}{k!}
    %\begin{pmatrix}
    %\bovermat{k zero columns}{0&\dots&0}&1&\\
    %&\ddots&&\ddots&\ddots&\\
    %&&0&\dots&0&1\\
    %&&&0&\dots&0\\
    %&&&&\ddots&\vdots\\
    %&&&&&0
    %\end{pmatrix}
    \begin{pmatrix}
    \bovermat{$k$ zeros}{0&\dots&0}&1&\\
    &\ddots&&\ddots&\ddots&\\
    &&\ddots&&\ddots&1\\
    &&&\ddots&&0\\
    &&&&\ddots&\vdots\\
    &&&&&0
    \end{pmatrix}
    +\dots+\frac{t^{n-1}}{(n-1)!}
    \begin{pmatrix}
    \bovermat{$n-1$ zeros}{0&\dots&0}&1\\
     &\ddots&&0\\
     & & \ddots & \vdots\\
     & & & 0\\
    \end{pmatrix}\\
    &=
    \begin{pmatrix}
    1 & t/1! & \dots & t/k! & \dots & t^{n-1}/(n-1)!\\
      & \ddots & \ddots &  & \ddots & \vdots\\
      & & 1 & t/1! & & t/k! &\\
      & & & \ddots & \ddots & \vdots\\
      & & & & 1 & t/1!\\
      & & & & & 1\\
    \end{pmatrix}
\end{align*}
We deduce from the previous expression that for $i\in [n]$:
\begin{equation*}
    x_i(t)=e^{\lambda t}\sum^{n}_{j=i}\frac{1}{(j-i)!}t^{j-i}x_i(0)
\end{equation*}
\subsection*{A3}
The minimal polynomial of a matrix \(A \in \complex^{n \times n}\) is the polynomial
\[
m(\lambda) = \prod_i (\lambda - \lambda_i)^{k_i^*},
\]
where
\[
f(J) = \mathop{\mathrm{diag}} \left\{f\left(J_{k_{i_j}}(\lambda_{i_j})\right)\right\}, \quad k_i^* = \max_{1 \leqslant j \leqslant n_i} k_{i_j},
\]
and \(n_i\) is the number of Jordan blocks with eigenvalue \(\lambda_i\).

If \(\lambda_i\) is a simple eigenvalue, then the size of the largest Jordan block with eigenvalue \(\lambda_i\) is \(1\) (i.e. \(k_i^* = 1\)).
\subsection*{A4}
\subsection*{A5}
\subsection*{A6}
\subsection*{A7}
\subsection*{A8}

\section*{Exercise B: Implementation}
\subsection*{B1}
\subsection*{B2}
\end{document}