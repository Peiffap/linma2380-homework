\documentclass[11pt]{article}
\usepackage[a4paper,left=1.5cm,right=1.5cm,top=1.5cm,bottom=1.5cm]{geometry}
\usepackage{fancyhdr}
\usepackage{mleftright}
\usepackage{verbatim}
\renewcommand{\headrulewidth}{1pt}
\fancyhead[C]{\textsc{[LINMA2380] --- Homework 3}}
\fancyhead[L]{23 November 2020}
\fancyhead[R]{Group 02}

\usepackage{tikz}
\usepackage{pgfplots}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{csquotes}
\usepackage{mathtools,amssymb,amsthm}
\usepackage[binary-units=true,separate-uncertainty = true,multi-part-units=single]{siunitx}
\usepackage{float}
\usepackage[linktoc=all]{hyperref}
\hypersetup{breaklinks=true}
\graphicspath{{img/}}
\usepackage{caption}
\usepackage{textcomp}
\usepackage{array}
\usepackage{color}
\usepackage{tabularx,booktabs}
\usepackage{titlesec}
\usepackage{wrapfig}
\pagestyle{fancy}
\usepackage{mathrsfs}
\usepackage{bm}
\DeclarePairedDelimiterX{\norm}[1]{\lVert}{\rVert}{#1}

\newcommand\bovermat[2]{%
  \makebox[0pt][l]{$\smash{\overbrace{\phantom{%
    \begin{matrix}#2\end{matrix}}}^{\text{#1}}}$}#2}
    
\newcommand{\imag}{\mathrm{i}\mkern1mu} % Imaginary unit
\newcommand{\abs}[1]{\left\lvert#1\right\lvert}
\newcommand{\kp}{\otimes}
\DeclareMathOperator{\vect}{vec}

\usepackage{listings}
\lstset{
	language=Python,
	numbers=left,
	numberstyle=\tiny\color{gray},
	basicstyle=\rm\small\ttfamily,
	keywordstyle=\bfseries\color{dkred},
	frame=single,
	commentstyle=\color{gray}=small,
	stringstyle=\color{dkgreen},
	%backgroundcolor=\color{gray!10},
	%tabsize=8, % Thank you Papa Torvalds
	%rulecolor=\color{black!30},
	%title=\lstname,
	breaklines=true,
	framextopmargin=2pt,
	framexbottommargin=2pt,
	extendedchars=true,
	inputencoding=utf8,
}

\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\vect}{vec}
\DeclareMathOperator{\newdiff}{d} % use \dif instead
\newcommand{\dif}{\newdiff\!}
\newcommand{\e}{\mathrm{e}}

\newcommand{\field}{\mathbb{F}} % field
\newcommand{\real}{\mathbb{R}} % real numbers
\newcommand{\complex}{\mathbb{C}} % complex numbers

\newcommand{\snorm}[1]{\norm{#1}_2} % spectral norm
\newcommand{\fnorm}[1]{\norm{#1}_F} % frobenius norm

\setcounter{MaxMatrixCols}{15}

\newcommand\undermat[2]{% http://tex.stackexchange.com/a/102468/5764
	\makebox[0pt][l]{$\smash{\underbrace{\phantom{%
					\begin{matrix}#2\end{matrix}}}_{\text{$#1$}}}$}#2}

\begin{document}
\section*{Exercise A: Boundedness of trajectories and Lyapunov equation}
\subsection*{A1}
The speed can by derived from the equality y(t) = T x(t):
\begin{align*}
    \Dot{y(t)} &= T \Dot{x(t)} \\
    &= T A x(t) \\
    &= T A T^{-1} y(t) \\
    &= diag\{J_1(\lambda_1), ..., J_r(\lambda_r)\} y(t)
\end{align*}

\subsection*{A2}
We assume that $A=J_n(\lambda)$. Hence we can write :
\begin{equation*}
    x(t)=e^{At}x(0)=e^{J_n(\lambda)t}x(0)
\end{equation*}
We can use the result of question B4 from Homework 1 which develops $e^{J_n(\lambda)}$:
\begin{align*}
    x(t)&=e^{J_n(\lambda)t}x(0)\\
    &=e^{\lambda t}\Bigg(I+\sum_{k=1}^{n-1}\frac{1}{k!}\big(J_n(0)\big)^k\Bigg)^t x(0)\\
    &=e^{\lambda t}e^{J_n(0) t} x(0)\\
    &=e^{\lambda t}\Bigg(I+\sum_{k=1}^{n-1}\frac{1}{k!}\big(J_n(0) t\big)^k\Bigg) x(0)\\
    &=e^{\lambda t}\Bigg(I+\sum_{k=1}^{n-1}\frac{1}{k!}J_n^k(0) t^k\Bigg) x(0)
\end{align*}
The third and fourth equalities come from the definition of the matrix exponential. We can now develop the terms in parentheses : 
\begin{align*}
    I+\sum_{k=1}^{n-1}\frac{1}{k!}J_n^k(0) t^k = I &+ \frac{t}{1!}
    \begin{pmatrix}
    0&1&&\\
    &\ddots&\ddots&&\\
    &&0&1&\\
    &&&0&1\\
    &&&&0
    \end{pmatrix} + \frac{t^2}{2!}
    \begin{pmatrix}
    0&0&1&\\
    &\ddots&\ddots&\ddots&\\
    &&0&0&1\\
    &&&0&0\\
    &&&&0
    \end{pmatrix}\\ \\
    &+ \dots +\frac{t^k}{k!}
    %\begin{pmatrix}
    %\bovermat{k zero columns}{0&\dots&0}&1&\\
    %&\ddots&&\ddots&\ddots&\\
    %&&0&\dots&0&1\\
    %&&&0&\dots&0\\
    %&&&&\ddots&\vdots\\
    %&&&&&0
    %\end{pmatrix}
    \begin{pmatrix}
    \bovermat{$k$ zeros}{0&\dots&0}&1&\\
    &\ddots&&\ddots&\ddots&\\
    &&\ddots&&\ddots&1\\
    &&&\ddots&&0\\
    &&&&\ddots&\vdots\\
    &&&&&0
    \end{pmatrix}
    +\dots+\frac{t^{n-1}}{(n-1)!}
    \begin{pmatrix}
    \bovermat{$n-1$ zeros}{0&\dots&0}&1\\
     &\ddots&&0\\
     & & \ddots & \vdots\\
     & & & 0\\
    \end{pmatrix}\\
    &=
    \begin{pmatrix}
    1 & t/1! & \dots & t/k! & \dots & t^{n-1}/(n-1)!\\
      & \ddots & \ddots &  & \ddots & \vdots\\
      & & 1 & t/1! & & t/k! &\\
      & & & \ddots & \ddots & \vdots\\
      & & & & 1 & t/1!\\
      & & & & & 1\\
    \end{pmatrix}
\end{align*}
We deduce from the previous expression that for $i\in [n]$:
\begin{equation*}
    x_i(t)=e^{\lambda t}\sum^{n}_{j=i}\frac{1}{(j-i)!}t^{j-i}x_j(0)
\end{equation*}
\subsection*{A3}
The minimal polynomial of a matrix \(A \in \complex^{n \times n}\) is the polynomial
\[
m(\lambda) = \prod_i (\lambda - \lambda_i)^{k_i^*},
\]
where
\[
f(J) = \mathop{\mathrm{diag}} \left\{f\left(J_{k_{i_j}}(\lambda_{i_j})\right)\right\}, \quad k_i^* = \max_{1 \leqslant j \leqslant n_i} k_{i_j},
\]
and \(n_i\) is the number of Jordan blocks with eigenvalue \(\lambda_i\).

Simple eigenvalues thus have the property that the size of the largest Jordan block with that eigenvalue \(\lambda_i\) is \(1\) (i.e. \(k_i^* = 1\)).
\subsection*{A4}
=>\\
By A1, we know there exists a change of coordinates $y=Tx$ such that $y(t)$ can be decomposed as follows: $y(t) = [y_1(t)^T, . . . , y_r(t)^T]^T$,where each $y_i(t)$, $i \in [r]$, is the trajectory of a continuous-time linear dynamical system with a Jordan block as transition matrix.\\
By A2, we have an expression for the time course of the components $y_i(t)$.\\
If $\lambda_i$ is such that $Re(\lambda_i)<0$, then from A2 we clearly see that the expression $y_i(t)$ tends to zero. If $\lambda_i$ is such that $Re(\lambda_i)<0$, by A3 we know the size of the largest Jordan block with that eigenvalue is 1, hence the expression of $y_i(t)$ simplifies to $y_i(t)=e^{\lambda t} y_j(0)$ which tends to zero when t tends to infinity.\\
We've shown $y_i(t)$ and hence $\norm{y(t)}=\norm{Tx(t)}$ tends to zero.
\subsection*{A5}
% not really sure this is what they're asking for
\begin{proof}
	One can show that the matrix \(P\) must exist by proving that for \(P = I_n\), the statement holds.
	Indeed, \(I_n\) is positive definite and Hermitian.
	Since \(D\) and \(D^*\) are diagonal, their sum is also diagonal.
	In fact,
	\[
	D + D^* = \mathop{\mathrm{diag}}(\lambda_1 + \lambda_1^*, \dots, \lambda_n + \lambda_n^*),
	\]
	where \(\lambda_i\) and \(\lambda_i^*\) are the eigenvalues of \(D\) and \(D^*\), respectively.
	We know that the imaginary parts of these eigenvalues cancel each other out, and that the real parts are the same (and are nonpositive), by virtue of the definition of the conjugate transpose.
	We thus get
	\[
	D^*P + PD = D^*I_n + I_nD = D^* + D = \mathop{\mathrm{diag}}(\lambda_1 + \lambda_1^*, \dots, \lambda_n + \lambda_n^*) \preceq 0,
	\]
	which proves the existence of such a positive definite Hermitian matrix \(P\).
\end{proof}
\subsection*{A6}
First, we develop $B=I\kp A^*+A^T\kp I$:
\begin{align*}
    B=
    \begin{pmatrix}
    A^* & & \\
    &\ddots&\\
    & & A^*
    \end{pmatrix}+
    \begin{pmatrix}
    a_{11} I & \dots & a_{1n} I\\
    \vdots & & \vdots\\
    a_{n1} I & \dots & a_{nn} I\\
    \end{pmatrix}
\end{align*}
We know $A\in\complex^{n\times n}$ is a Jordan block with eigenvalue $\lambda$:
\begin{align*}
    B&=
    \renewcommand{\arraystretch}{1.5}
    \begin{pmatrix}
    J_n(\lambda)^* & & \\
    &\ddots&\\
    & & J_n(\lambda)^*
    \end{pmatrix}+
    \begin{pmatrix}
    \lambda I & & &\\
    I & \ddots & &\\
    & \ddots & \ddots &\\
    & & I & \lambda I
    \end{pmatrix}\\
    &=\begin{pmatrix}
    J_n(\lambda)^*+\lambda I &  &  & \\
    I & \ddots & &\\
    & \ddots & \ddots &\\
    & & I & J_n(\lambda)^*+\lambda I
    \end{pmatrix}\\
    &=\begin{pmatrix}
    J_n(\lambda+\lambda^*)^* & & & \\
    I & \ddots & &\\
    & \ddots & \ddots &\\
    & & I & J_n(\lambda+\lambda^*)^*
    \end{pmatrix}
\end{align*}
The matrix B is a lower triangular and therefore its eigenvalues are the diagonal elements : $\lambda+\lambda^*$. Moreover, we know $Re(\lambda)>0$ and so $\lambda+\lambda^*=2Re(\lambda)>0$. From this we deduce that $B$ is positive definite and hence invertible. It follows that the system $B\vect(P)=-\vect(Q)$ has a unique solution and consequently we conclude that P exists and is unique.\\
Next we show that if $P\in\complex^{n\times n}$ satisfies $A^*P+PA=-Q$ then $P^*$ also satisfies $A^*P^*+P^*A=-Q$. This can be simply proven by taking the transpose conjuguate of both sides of the equation $A^*P+PA=-Q$ that P satisfies taking into account that Q is hermitian:
\begin{align*}
    (A^*P+PA)^*&=(-Q)^*\\
    P^*A+A^*P^*&=-Q
\end{align*}
This shows that $P^*$ satisfies $A^*P^*+P^*A=-Q$.\\
Combining the two last results, we deduce that there always exists a unique hermitian matrix $P$ satisfying $B\vect(P)=-\vect(Q)$.\\
Finally, we want to show that $P$ is hermitian. We consider a trajectory $x(t)$ starting from $x(0)$. If we define $V(x(t))=x(t)^*Px(t)$, we observe that:
\begin{align*}
    \dot{V}(x(t))&=\dot{x}(t)^*P x(t)+x(t)^*P\dot{x}(t)\\
    &=x(t)^*A^*P x(t)+x(t)^*P A x(t)\\
    &=x(t)^*(A^*P+P A) x(t)\\
    &=x(t)^*(-Q) x(t)\\
    &\leq 0
\end{align*}
Consequently, we find that for $t>0$ we have: $x(t)^*P x(t)< x(0)^*P x(0)$.
%%%% TROUVER LA DERNIERE PARTIE
\subsection*{A7}
2 => 3\\
%IDEE
% prouver pourquoi on peut considerer la jordan form
Jordan form of A such that simple eigenvalues in block $A_1$ and other eigenvalues in block $A_2$:
\begin{align*}
    \begin{pmatrix}
    A_1 & \\
    & A_2
    \end{pmatrix}
\end{align*}
By A3 we find $P_1$ such that $P_1A_1+A_1^*P_1=-Q1$ and by A6 we find $P_2$ such that $P_2A_2+A_2^*P_2=-Q2$
\begin{align*}
    \begin{pmatrix}
    P_1 & \\
    & P_2
    \end{pmatrix}
    \begin{pmatrix}
    A_1 & \\
    & A_2
    \end{pmatrix}
    +
    \begin{pmatrix}
    A_1^* & \\
    & A_2^*
    \end{pmatrix}
    \begin{pmatrix}
    P_1 & \\
    & P_2
    \end{pmatrix}=-
    \begin{pmatrix}
    Q_1 & \\
    & Q_2
    \end{pmatrix}\preceq 0
\end{align*}

\subsection*{A8}

\section*{Exercise B: Implementation}
\subsection*{B1}
\subsection*{B2}
\end{document}